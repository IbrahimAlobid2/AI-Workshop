{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "838b738b-4566-41a3-bde0-5800fe16572d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import openai \n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.messages import  HumanMessage\n",
    "from groq import Groq\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d64123c0-5b09-49af-bd10-60604843fdd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "GROQ_API = os.getenv(\"GROQ_API_KEY\")\n",
    "model_name = 'gemma2-9b-it'\n",
    "\n",
    "\n",
    "llm  =  ChatGroq(api_key=GROQ_API,\n",
    "    model_name=model_name,\n",
    "    temperature=0.0,\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151751b7-49c9-4491-b767-5cdfba324de3",
   "metadata": {},
   "source": [
    "## Test API "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de47f526-52a8-4c91-9f28-8561f685710f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Tell me about Alepp in Arabic language\"\n",
    "\n",
    "messages = [HumanMessage(content=prompt)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37ec168b-dda5-4c45-935a-80895d4bb598",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Ø­Ù„Ø¨ (Aleppo)\n",
       "\n",
       "Ø­Ù„Ø¨ØŒ Ù…Ø¯ÙŠÙ†Ø© ØªØ§Ø±ÙŠØ®ÙŠØ© Ø¹Ø±ÙŠÙ‚Ø©ØŒ ØªÙ‚Ø¹ ÙÙŠ Ø´Ù…Ø§Ù„ Ø³ÙˆØ±ÙŠØ§ØŒ ÙˆØªÙØ¹ØªØ¨Ø± Ù…Ù† Ø£Ù‚Ø¯Ù… Ø§Ù„Ù…Ø¯Ù† ÙÙŠ Ø§Ù„Ø¹Ø§Ù„Ù…ØŒ Ø­ÙŠØ« ÙŠØ¹ÙˆØ¯ ØªØ§Ø±ÙŠØ®Ù‡Ø§ Ø¥Ù„Ù‰ Ø¢Ù„Ø§Ù Ø§Ù„Ø³Ù†ÙŠÙ†. \n",
       "\n",
       "**ØªØ§Ø±ÙŠØ® Ø­Ù„Ø¨:**\n",
       "\n",
       "* ÙƒØ§Ù†Øª Ø­Ù„Ø¨ Ù…Ø±ÙƒØ²Ù‹Ø§ ØªØ¬Ø§Ø±ÙŠÙ‹Ø§ Ù‡Ø§Ù…Ù‹Ø§ ÙÙŠ Ø§Ù„Ø¹ØµÙˆØ± Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø©ØŒ ÙˆÙƒØ§Ù†Øª ØªØ­Øª Ø³ÙŠØ·Ø±Ø© Ø§Ù„Ø¹Ø¯ÙŠØ¯ Ù…Ù† Ø§Ù„Ø¥Ù…Ø¨Ø±Ø§Ø·ÙˆØ±ÙŠØ§ØªØŒ Ù…Ø«Ù„ Ø§Ù„Ø¥Ù…Ø¨Ø±Ø§Ø·ÙˆØ±ÙŠØ© Ø§Ù„Ø¢Ø´ÙˆØ±ÙŠØ©ØŒ ÙˆØ§Ù„Ø±ÙˆÙ…Ø§Ù†ÙŠØ©ØŒ ÙˆØ§Ù„Ø¨ÙŠØ²Ù†Ø·ÙŠØ©ØŒ ÙˆØ§Ù„Ø¹Ø¨Ø§Ø³ÙŠØ©.\n",
       "* Ø´Ù‡Ø¯Øª Ø­Ù„Ø¨ Ø§Ø²Ø¯Ù‡Ø§Ø±Ù‹Ø§ ÙƒØ¨ÙŠØ±Ù‹Ø§ ÙÙŠ Ø§Ù„Ø¹ØµØ± Ø§Ù„Ø¹Ø¨Ø§Ø³ÙŠØŒ ÙˆØ£ØµØ¨Ø­Øª Ù…Ø±ÙƒØ²Ù‹Ø§ Ø«Ù‚Ø§ÙÙŠÙ‹Ø§ ÙˆÙÙ†ÙŠÙ‹Ø§.\n",
       "* ÙÙŠ Ø§Ù„Ø¹ØµÙˆØ± Ø§Ù„ÙˆØ³Ø·Ù‰ØŒ ÙƒØ§Ù†Øª Ø­Ù„Ø¨ Ø¬Ø²Ø¡Ù‹Ø§ Ù…Ù† Ø§Ù„Ø¯ÙˆÙ„Ø© Ø§Ù„Ù…Ù…Ù„ÙˆÙƒÙŠØ©ØŒ Ø«Ù… Ø§Ù„Ø¯ÙˆÙ„Ø© Ø§Ù„Ø¹Ø«Ù…Ø§Ù†ÙŠØ©.\n",
       "* ÙÙŠ Ø§Ù„Ù‚Ø±Ù† Ø§Ù„Ø¹Ø´Ø±ÙŠÙ†ØŒ Ø£ØµØ¨Ø­Øª Ø­Ù„Ø¨ Ø¹Ø§ØµÙ…Ø© Ù…Ø­Ø§ÙØ¸Ø© Ø­Ù„Ø¨.\n",
       "\n",
       "**Ø§Ù„Ù…Ø¹Ø§Ù„Ù… Ø§Ù„Ø³ÙŠØ§Ø­ÙŠØ© ÙÙŠ Ø­Ù„Ø¨:**\n",
       "\n",
       "* **Ø§Ù„Ù‚Ù„Ø¹Ø©:** Ù‚Ù„Ø¹Ø© Ø­Ù„Ø¨ØŒ ÙˆÙ‡ÙŠ Ù‚Ù„Ø¹Ø© ØªØ§Ø±ÙŠØ®ÙŠØ© Ø¶Ø®Ù…Ø©ØŒ Ø¨Ù†ÙŠØª ÙÙŠ Ø§Ù„Ø¹ØµØ± Ø§Ù„Ø¹Ø¨Ø§Ø³ÙŠ.\n",
       "* **Ø§Ù„Ù…Ø³Ø¬Ø¯ Ø§Ù„ÙƒØ¨ÙŠØ±:** Ù…Ø³Ø¬Ø¯ ØªØ§Ø±ÙŠØ®ÙŠ Ø¹Ø±ÙŠÙ‚ØŒ ÙŠÙ‚Ø¹ ÙÙŠ Ù‚Ù„Ø¨ Ø§Ù„Ù…Ø¯ÙŠÙ†Ø© Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø©.\n",
       "* **Ø³ÙˆÙ‚ Ø­Ù„Ø¨:** Ø³ÙˆÙ‚ Ø´Ø¹Ø¨ÙŠ Ø¶Ø®Ù…ØŒ ÙŠØ¶Ù… Ø§Ù„Ø¹Ø¯ÙŠØ¯ Ù…Ù† Ø§Ù„Ù…Ø­Ù„Ø§Øª Ø§Ù„ØªØ¬Ø§Ø±ÙŠØ©ØŒ ÙˆÙŠÙØ¹ØªØ¨Ø± Ù…Ù† Ø£Ø´Ù‡Ø± Ø§Ù„Ø£Ø³ÙˆØ§Ù‚ ÙÙŠ Ø§Ù„Ø¹Ø§Ù„Ù….\n",
       "* **Ø§Ù„Ù…ØªØ­Ù Ø§Ù„ÙˆØ·Ù†ÙŠ:** ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø§Ù„Ø¹Ø¯ÙŠØ¯ Ù…Ù† Ø§Ù„ØªØ­Ù Ø§Ù„Ø£Ø«Ø±ÙŠØ© Ù…Ù† Ø§Ù„Ø¹ØµÙˆØ± Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø©.\n",
       "* **Ø¬Ø§Ù…Ø¹Ø© Ø­Ù„Ø¨:** Ø¬Ø§Ù…Ø¹Ø© ØªØ§Ø±ÙŠØ®ÙŠØ©ØŒ ØªØ£Ø³Ø³Øª ÙÙŠ Ø§Ù„Ù‚Ø±Ù† Ø§Ù„Ø¹Ø´Ø±ÙŠÙ†.\n",
       "\n",
       "**Ø§Ù„Ø«Ù‚Ø§ÙØ© ÙˆØ§Ù„Ø­ÙŠØ§Ø© ÙÙŠ Ø­Ù„Ø¨:**\n",
       "\n",
       "* Ø­Ù„Ø¨ Ù…Ø¯ÙŠÙ†Ø© Ø¹Ø±ÙŠÙ‚Ø©ØŒ ØªØªÙ…ÙŠØ² Ø¨Ø«Ù‚Ø§ÙØ© ØºÙ†ÙŠØ©ØŒ ÙˆØªØ§Ø±ÙŠØ® Ø·ÙˆÙŠÙ„.\n",
       "* ØªØªÙ…ØªØ¹ Ø­Ù„Ø¨ Ø¨Ù…Ù†Ø§Ø® Ù…Ø¹ØªØ¯Ù„ØŒ ÙˆØ·Ø¨ÙŠØ¹Ø© Ø¬Ù…ÙŠÙ„Ø©.\n",
       "* Ø³ÙƒØ§Ù† Ø­Ù„Ø¨ Ù…Ø¹Ø±ÙˆÙÙˆÙ† Ø¨Ø¶ÙŠØ§ÙØªÙ‡Ù…ØŒ ÙˆØ±ÙˆØ­Ù‡Ù… Ø§Ù„Ù…Ø±Ø­Ø©.\n",
       "\n",
       "**Ø§Ù„ÙˆØ¶Ø¹ Ø§Ù„Ø­Ø§Ù„ÙŠ:**\n",
       "\n",
       "* Ø­Ù„Ø¨ Ù…Ø¯ÙŠÙ†Ø© ØªØ¹Ø§Ù†ÙŠ Ù…Ù† Ø¢Ø«Ø§Ø± Ø§Ù„Ø­Ø±Ø¨ØŒ ÙˆÙ„ÙƒÙ†Ù‡Ø§ Ù…Ø§ Ø²Ø§Ù„Øª Ù…Ø¯ÙŠÙ†Ø© Ø¬Ù…ÙŠÙ„Ø©ØŒ ÙˆØªØªÙ…ØªØ¹ Ø¨ØªØ§Ø±ÙŠØ® Ø¹Ø±ÙŠÙ‚.\n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = llm.invoke(messages)\n",
    "\n",
    "display(Markdown(response.content))\n",
    "#print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c800d66d-17cc-4b90-8132-7f23869d7739",
   "metadata": {},
   "source": [
    "## Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42f3a116-31e3-451c-92e4-48e107f5e6c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt template input_variables=['company_name', 'customer_review'] input_types={} partial_variables={} messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['company_name', 'customer_review'], input_types={}, partial_variables={}, template=' \\n  the followingTranslate text {customer_review}\\n into German in a polite tone.\\n And the company name is {company_name}\\n'), additional_kwargs={})]\n"
     ]
    }
   ],
   "source": [
    "# Translate text, review \n",
    "customer_review = \"\"\"\n",
    " Your product is terrible!  I don't know how \n",
    " you were able to get this to the market.\n",
    " I don't want this! Actually no one should want this.\n",
    " Seriously!  Give me money now!\n",
    " \"\"\"\n",
    "\n",
    "template_string = \"\"\" \n",
    "  the followingTranslate text {customer_review}\n",
    " into German in a polite tone.\n",
    " And the company name is {company_name}\n",
    "\"\"\"\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_template(template_string)\n",
    "print(f\"prompt template {prompt_template}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0bc0116-a88a-451e-a03f-fcd39e8ffeb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "translation message [HumanMessage(content=\" \\n  the followingTranslate text \\n Your product is terrible!  I don't know how \\n you were able to get this to the market.\\n I don't want this! Actually no one should want this.\\n Seriously!  Give me money now!\\n \\n into German in a polite tone.\\n And the company name is Alibaba\\n\", additional_kwargs={}, response_metadata={})]\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Sehr geehrte Damen und Herren von Alibaba,\n",
       "\n",
       "ich bin sehr enttÃ¤uscht von Ihrem Produkt. \n",
       "\n",
       "Es entspricht leider nicht meinen Erwartungen. \n",
       "\n",
       "Ich wÃ¼rde mich freuen, wenn wir eine LÃ¶sung finden kÃ¶nnten. \n",
       "\n",
       "Mit freundlichen GrÃ¼ÃŸen,\n",
       "\n",
       "[Your Name]\n",
       "\n",
       "\n",
       "**Explanation:**\n",
       "\n",
       "This translation avoids direct insults and focuses on expressing disappointment and seeking a resolution. \n",
       "\n",
       "Here's a breakdown:\n",
       "\n",
       "* **\"Sehr geehrte Damen und Herren von Alibaba\"**: This is a polite way to address Alibaba as a company.\n",
       "* **\"ich bin sehr enttÃ¤uscht von Ihrem Produkt\"**: This expresses disappointment without being aggressive.\n",
       "* **\"Es entspricht leider nicht meinen Erwartungen\"**: This explains the reason for the disappointment without blaming Alibaba directly.\n",
       "* **\"Ich wÃ¼rde mich freuen, wenn wir eine LÃ¶sung finden kÃ¶nnten\"**: This shows a willingness to work with Alibaba to find a solution.\n",
       "* **\"Mit freundlichen GrÃ¼ÃŸen\"**: This is a polite closing for a business letter.\n",
       "\n",
       "\n",
       "**Important Note:**\n",
       "\n",
       "While this translation is more polite, it's important to remember that the original message expresses strong dissatisfaction.  It's best to be honest about your concerns while maintaining a respectful tone. \n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "translation_message = prompt_template.format_messages(\n",
    "    customer_review = customer_review,\n",
    "    company_name=\"Alibaba\"\n",
    ")\n",
    "print(f\"translation message {translation_message}\\n\\n\\n\")\n",
    "response = llm.invoke(translation_message)\n",
    "display(Markdown(response.content))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c1c1d4-1cc7-4d20-becf-df902276c4a2",
   "metadata": {},
   "source": [
    "##  Output Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "948e5f2f-98b9-4023-9c12-c46bc040378b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import openai \n",
    "from dotenv import load_dotenv\n",
    "from groq import Groq\n",
    "from langchain_groq import ChatGroq\n",
    "#from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.output_parsers import ResponseSchema\n",
    "from langchain.output_parsers import StructuredOutputParser\n",
    "#from langchain_core.output_parsers import StrOutputParser\n",
    "load_dotenv()\n",
    "GROQ_API = os.getenv(\"GROQ_API_KEY\")\n",
    "model_name = 'qwen-2.5-32b'\n",
    "\n",
    "chat =ChatGroq(api_key=GROQ_API,\n",
    "    model_name=model_name,\n",
    "    temperature=0.0,\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf0c07d3-0ba2-432c-bfb6-5fc7ceef2f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "email_response = \"\"\"\n",
    "Here's our itinerary for our upcoming trip to Europe.\n",
    "We leave from Denver, Colorado airport at 8:45 pm, and arrive in Amsterdam 10 hours later\n",
    "at Schipol Airport.\n",
    "We'll grab a ride to our airbnb and maybe stop somewhere for breakfast before \n",
    "taking a nap.\n",
    "\n",
    "Some sightseeing will follow for a couple of hours. \n",
    "We will then go shop for gifts \n",
    "to bring back to our children and friends.  \n",
    "\n",
    "The next morning, at 7:45am we'll drive to to Belgium, Brussels - it should only take aroud 3 hours.\n",
    "While in Brussels we want to explore the city to its fullest - no rock left unturned!\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "email_template = \"\"\"\n",
    "From the following email, extract the following information:\n",
    "\n",
    "leave_time: when are they leaving for vacation to Europe. If there's an actual\n",
    "time written, use it, if not write unknown.\n",
    "\n",
    "leave_from: where are they leaving from, the airport or city name and state if\n",
    "available.\n",
    "\n",
    "cities_to_visit: extract the cities they are going to visit. \n",
    "If there are more than one, put them in square brackets like '[\"cityone\", \"citytwo\"].\n",
    "\n",
    "Format the output as JSON with the following keys:\n",
    "leave_time\n",
    "leave_from\n",
    "cities_to_visit\n",
    "\n",
    "email: {email}\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "daa0746b-7074-4e5f-9ff6-cc75b48b058b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"leave_time\": \"8:45 pm\",\n",
      "  \"leave_from\": \"Denver, Colorado\",\n",
      "  \"cities_to_visit\": [\"Amsterdam\", \"Brussels\"]\n",
      "}\n",
      "```\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "prompt_template = ChatPromptTemplate.from_template(email_template)\n",
    "messages = prompt_template.format_messages(email=email_response)\n",
    "response = chat.invoke(messages)\n",
    "\n",
    "print(response.content)\n",
    "print(type(response.content))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f29bbe3-342e-4469-a75d-e24d70eb658b",
   "metadata": {},
   "source": [
    "### Response Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ebda367-7490-4e3f-a0ef-a19b41df4248",
   "metadata": {},
   "outputs": [],
   "source": [
    "leave_time_schema = ResponseSchema(name=\"leave_time\",\n",
    "                                   description=\"When they are leaving. \\\n",
    "                                       It's usually a numberical time of the day. \\\n",
    "                                           If not available wirte n/a\")\n",
    "leave_from_schema = ResponseSchema(name=\"leave_from\",\n",
    "                                      description=\"Where are they leaving from.\\\n",
    "                                          it's a city, airport or state, or province\")\n",
    "cities_to_visit_schema = ResponseSchema(name=\"cities_to_visit\",\n",
    "                                    description=\"The cities, towns they will be visiting on \\\n",
    "                                        their trip. This needs to be in a list\")\n",
    "\n",
    "response_schema = [\n",
    "    leave_time_schema,\n",
    "    leave_from_schema,\n",
    "    cities_to_visit_schema\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca1ad182-6a0f-496d-9206-54ea7a22b7a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
      "\n",
      "```json\n",
      "{\n",
      "\t\"leave_time\": string  // When they are leaving.                                        It's usually a numberical time of the day.                                            If not available wirte n/a\n",
      "\t\"leave_from\": string  // Where are they leaving from.                                          it's a city, airport or state, or province\n",
      "\t\"cities_to_visit\": string  // The cities, towns they will be visiting on                                         their trip. This needs to be in a list\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# setup the output parser\n",
    "output_parser = StructuredOutputParser.from_response_schemas(response_schema)\n",
    "\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "print(format_instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "18d88177-5c40-4d2c-b7d4-a15a1bd661eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "email_template_revised = \"\"\"\n",
    "From the following email, extract the following information:\n",
    "\n",
    "leave_time: when are they leaving for vacation to Europe. If there's an actual\n",
    "time written, use it, if not write unknown.\n",
    "\n",
    "leave_from: where are they leaving from, the airport or city name and state if\n",
    "available.\n",
    "\n",
    "cities_to_visit: extract the cities they are going to visit. If there are more than \n",
    "one, put them in square brackets like '[\"cityone\", \"citytwo\"].\n",
    "\n",
    "Format the output as JSON with the following keys:\n",
    "leave_time\n",
    "leave_from\n",
    "cities_to_visit\n",
    "\n",
    "email: {email}\n",
    "{format_instructions}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "54ef452d-2b23-4dc5-93cc-9853864d57d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"leave_time\": \"8:45 pm\",\n",
      "  \"leave_from\": \"Denver, Colorado\",\n",
      "  \"cities_to_visit\": [\"Amsterdam\", \"Brussels\"]\n",
      "}\n",
      "```\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "updated_prompt = ChatPromptTemplate.from_template(template=email_template_revised)\n",
    "\n",
    "messages = prompt_template.format_messages(email=email_response,\n",
    "                                           format_instructions=format_instructions)\n",
    "\n",
    "response = chat.invoke(messages)\n",
    "\n",
    "print(response.content)\n",
    "print(type(response.content))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e116d7f-a97c-4e2c-9a51-03056ea4089d",
   "metadata": {},
   "source": [
    "## parse into dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "954b357d-6b90-4352-b874-25aa8e5c1b16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "output_dict = output_parser.parse(response.content) \n",
    "print(type(output_dict))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6debe7c7-5796-4c57-af8c-0931faae7f04",
   "metadata": {},
   "source": [
    "# memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "667ffd58-e63c-4848-b59e-bd907240802d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hi, my name is Ibrahim Alobaid\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi, my name is Ibrahim Alobaid\n",
      "AI: Hello Ibrahim Alobaid, it's nice to meet you!  I'm an AI assistant, ready to help with any questions or tasks you might have. What can I do for you today? \n",
      "\n",
      "\n",
      "Human: What is 1+1?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi, my name is Ibrahim Alobaid\n",
      "AI: Hello Ibrahim Alobaid, it's nice to meet you!  I'm an AI assistant, ready to help with any questions or tasks you might have. What can I do for you today? \n",
      "\n",
      "\n",
      "Human: What is 1+1?\n",
      "AI: 1 + 1 = 2 \n",
      "\n",
      "\n",
      "Human: What is my name?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'history': \"Human: Hi, my name is Ibrahim Alobaid\\nAI: Hello Ibrahim Alobaid, it's nice to meet you!  I'm an AI assistant, ready to help with any questions or tasks you might have. What can I do for you today? \\n\\n\\nHuman: What is 1+1?\\nAI: 1 + 1 = 2 \\n\\n\\nHuman: What is my name?\\nAI: Your name is Ibrahim Alobaid.  ğŸ˜Š \\n\"}\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationChain\n",
    "memory = ConversationBufferMemory()\n",
    "\n",
    "conversation = ConversationChain(\n",
    "llm=llm, \n",
    "memory = memory,\n",
    "verbose=True\n",
    ")\n",
    "conversation.predict(input=\"Hi, my name is Ibrahim Alobaid\")\n",
    "conversation.predict(input=\"What is 1+1?\")\n",
    "conversation.predict(input=\"What is my name?\")\n",
    "\n",
    "print( memory.load_memory_variables({}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a174e668-bbac-4cc1-8497-a052bf610fa0",
   "metadata": {},
   "source": [
    "# chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "74089e16-f944-4fb2-971e-690b3d6d224b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good morning in German is said as \"Guten Morgen.\"\n"
     ]
    }
   ],
   "source": [
    "\n",
    "llm =  ChatGroq(api_key=GROQ_API,\n",
    "    model_name=model_name,\n",
    "    temperature=0.0,\n",
    ")\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"language\"],\n",
    "    template=\"How do you say good morning in {language}?\"\n",
    ")\n",
    "\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "result = chain.invoke({\"language\": \"German\"})\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70bed836-bf14-4528-9c99-f029c566a51b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the land of Syria, under the vast sky so clear,\n",
      "Lies a village where Ibrahim dreams, as the olive trees whisper near.\n",
      "Moon above, stars to guide, in the soft night's embrace,\n",
      "Ibrahim, my dear, let the gentle winds cradle your grace.\n",
      "Sleep, little one, sleep, as the Euphrates softly flows,\n",
      "Dream of the ancient tales, where the desert and rivers close.\n",
      "In the arms of the night, in the heart of the land,\n",
      "Dream, Ibrahim, dream, in your homeland so grand.\n"
     ]
    }
   ],
   "source": [
    "llm = ChatGroq(\n",
    "    api_key=GROQ_API,\n",
    "    model_name=model_name,\n",
    "    temperature=0.0,\n",
    ")\n",
    "\n",
    "template = \"\"\" \n",
    " As a children's book writer, please come up with a simple and short (90 words)\n",
    " lullaby based on the location\n",
    " {location}\n",
    " and the main character {name}\n",
    " STORY:\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(input_variables=[\"location\", \"name\" , 'language'],\n",
    "                        template=template)\n",
    "\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "\n",
    "result = chain.invoke({\"location\": \"Syria\", \"name\": \"Mary\" , 'language': 'English'})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd05d1a-baab-44e5-b476-ddf5570cc541",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_langchain",
   "language": "python",
   "name": "env_langchain"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
