{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4ea6db3-eb43-460c-9b4b-f5c85021ebe3",
   "metadata": {},
   "source": [
    "# AI-Recipe-Generator\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3aee2bb7-e90e-4392-b05b-2c508fc04343",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from groq import Groq\n",
    "import base64\n",
    "import streamlit as st\n",
    "import requests\n",
    "\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b2a53c1-fea7-4224-ade8-8054a9da53ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(find_dotenv())\n",
    "GROQ_API = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "model_name = 'llama-3.3-70b-versatile'\n",
    "llm  =  ChatGroq(api_key=GROQ_API,\n",
    "    model_name=model_name,\n",
    "    temperature=0.0,\n",
    "    \n",
    ")\n",
    "\n",
    "client = Groq(api_key= GROQ_API)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25fff4fc-db3e-427e-9da4-2f432831b1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_image(image_path):\n",
    "  with open(image_path, \"rb\") as image_file:\n",
    "    return base64.b64encode(image_file.read()).decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6d07d986-6acd-48a3-973d-49fa2de3e465",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_to_text(url):\n",
    "    base64_image = encode_image(url)\n",
    "    completion = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": \"What's in this image?\"},\n",
    "                    {\n",
    "                        \"type\": \"image_url\",\n",
    "                        \"image_url\": {\n",
    "                            \"url\": f\"data:image/jpeg;base64,{base64_image}\",\n",
    "                        },\n",
    "                    },\n",
    "                ],\n",
    "            }\n",
    "        ],\n",
    "        model=\"llama-3.2-11b-vision-preview\",\n",
    "    )\n",
    "    text = completion.choices[0].message\n",
    "    return text\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7a2da17b-a19a-4171-8f62-9c0349e77e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_recipe(ingredients):\n",
    "    template = \"\"\"\n",
    "    You are a extremely knowledgeable nutritionist, bodybuilder and chef who also knows\n",
    "                everything one needs to know about the best quick, healthy recipes. \n",
    "                You know all there is to know about healthy foods, healthy recipes that keep \n",
    "                people lean and help them build muscles, and lose stubborn fat.\n",
    "                \n",
    "                You've also trained many top performers athletes in body building, and in extremely \n",
    "                amazing physique. \n",
    "                \n",
    "                You understand how to help people who don't have much time and or \n",
    "                ingredients to make meals fast depending on what they can find in the kitchen. \n",
    "                Your job is to assist users with questions related to finding the best recipes and \n",
    "                cooking instructions depending on the following variables:\n",
    "                0/ {ingredients}\n",
    "                \n",
    "                When finding the best recipes and instructions to cook,\n",
    "                you'll answer with confidence and to the point.\n",
    "                Keep in mind the time constraint of 5-10 minutes when coming up\n",
    "                with recipes and instructions as well as the recipe.\n",
    "                \n",
    "                If the {ingredients} are less than 3, feel free to add a few more\n",
    "                as long as they will compliment the healthy meal.\n",
    "                \n",
    "            \n",
    "                Make sure to format your answer as follows:\n",
    "                - The name of the meal as bold title (new line)\n",
    "                - Best for recipe category (bold)\n",
    "                    \n",
    "                - Preparation Time (header)\n",
    "                    \n",
    "                - Difficulty (bold):\n",
    "                    Easy\n",
    "                - Ingredients (bold)\n",
    "                    List all ingredients \n",
    "                - Kitchen tools needed (bold)\n",
    "                    List kitchen tools needed\n",
    "                - Instructions (bold)\n",
    "                    List all instructions to put the meal together\n",
    "                - Macros (bold): \n",
    "                    Total calories\n",
    "                    List each ingredient calories\n",
    "                    List all macros \n",
    "                    \n",
    "                    Please make sure to be brief and to the point.  \n",
    "                    Make the instructions easy to follow and step-by-step .\n",
    "    \"\"\"\n",
    "    prompt = PromptTemplate(template=template, input_variables=[\"ingredients\"])\n",
    "    recipe_chain = prompt | llm\n",
    "    recipe = recipe_chain.invoke(ingredients)\n",
    "\n",
    "\n",
    "    return recipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c9081cd6-4250-4321-b437-3074785bbacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ingredients =image_to_text(\"mango_fruits.jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c6b95cff-dc07-468a-a221-85d70452f159",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The image displays a variety of fruits, including frozen strawberries and bananas, and several bowls of chopped fruit and a glass of water is included. In the lower-left corner of the image, there is a glasses filled with ice and a pitcher filled with water, with three lemon halves next to it. Scattered strawberries and an almond are below it. Above the water glasses, there are two bowls of chopped fruit: on the left is a white bowl with dark gray edging filled with diced yellow mango and a white bowl with black edging filled with whole strawberries that have been frozen. To the right is another white bowl with black edging filled with sliced yellow bananas. Above those are one final white bowl with a black edging filled with more yellow banana slices. Next to the bowls are bunches of ripe, yellow bananas; whole mangoes (one above the other); and almonds above a tall, silver measuring cup that that says \"1 TBSP\" on one side. In front of the measuring cups are a round measuring cup with brown liquid that says \"1 TBSP\" and a wide, white cup with an indentation in the shape of a bowl. The cups are placed on a wooden table with natural wood grain."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "display(Markdown(ingredients.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8c01b181-f5f7-44ba-aa17-e68088d724c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "recipe = generate_recipe(ingredients=ingredients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "af431c2c-ea1d-4c7c-872d-c87731ea8a41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Mango Strawberry Banana Smoothie**\n",
       "**Best for:** **Post-Workout Recovery**, **Healthy Snack**, **Quick Breakfast**\n",
       "\n",
       "## Preparation Time\n",
       "5 minutes\n",
       "\n",
       "## Difficulty\n",
       "**Easy**\n",
       "\n",
       "## Ingredients\n",
       "* 1 ripe mango\n",
       "* 2 bananas\n",
       "* 1/2 cup sliced frozen strawberries\n",
       "* 1/2 cup whole strawberries\n",
       "* 1/2 cup ice\n",
       "* 1/2 cup water\n",
       "* 1 lemon slice\n",
       "* 1 tablespoon almond slivers\n",
       "* 1 tablespoon brown sugar\n",
       "* 2 tablespoons coconut cream\n",
       "\n",
       "## Kitchen tools needed\n",
       "* Blender\n",
       "* Cutting board\n",
       "* Knife\n",
       "* Measuring cups\n",
       "* Spoon\n",
       "\n",
       "## Instructions\n",
       "1. Add the mango, bananas, frozen strawberries, whole strawberries, ice, and water to a blender.\n",
       "2. Squeeze the lemon slice into the blender and add the almond slivers.\n",
       "3. Add the brown sugar and coconut cream to the blender.\n",
       "4. Blend the mixture on high speed until smooth and creamy.\n",
       "5. Pour the smoothie into a glass and serve immediately.\n",
       "\n",
       "## Macros\n",
       "* Total calories: 350\n",
       "* Mango: 100 calories\n",
       "* Bananas: 140 calories\n",
       "* Strawberries: 50 calories\n",
       "* Ice: 0 calories\n",
       "* Water: 0 calories\n",
       "* Lemon slice: 2 calories\n",
       "* Almond slivers: 50 calories\n",
       "* Brown sugar: 60 calories\n",
       "* Coconut cream: 100 calories\n",
       "* Protein: 5g\n",
       "* Fat: 15g\n",
       "* Carbohydrates: 50g\n",
       "* Fiber: 5g\n",
       "* Sugar: 30g\n",
       "* Sodium: 50mg"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "display(Markdown(recipe.content))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7919c900-5f2f-44ef-b8d1-ebc4860561c7",
   "metadata": {},
   "source": [
    "# AI-Invoice-Extractor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ca7c5f47-029b-4655-9f82-549773b9aef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pypdf import PdfReader\n",
    "import pandas as pd\n",
    "import re\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.agents.agent_types import AgentType\n",
    "from ast import literal_eval\n",
    "import os\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "from langchain_groq import ChatGroq\n",
    "from io import BytesIO\n",
    "from pypdf import PdfReader\n",
    "import pandas as pd\n",
    "import re\n",
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "be3d0f4d-804e-4781-b829-9ee116d80c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "GROQ_API = os.getenv(\"GROQ_API_KEY\")\n",
    "model_name = 'llama-3.3-70b-versatile'\n",
    "llm  =  ChatGroq(api_key=GROQ_API,\n",
    "    model_name=model_name,\n",
    "    temperature=0.0,\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "097ea337-a2fb-4e27-aba0-82474e0db2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modified PDF text extraction function\n",
    "def get_pdf_text(uploaded_file):\n",
    "    text = \"\"\n",
    "    # Create a bytes stream from uploaded file\n",
    "    pdf_bytes = BytesIO(uploaded_file.getvalue())\n",
    "    pdf_reader = PdfReader(pdf_bytes)\n",
    "    for page in pdf_reader.pages:\n",
    "        text += page.extract_text()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6a6d7895-c12a-4659-bc91-d02f90ace994",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extracted_data(pages_data):\n",
    "\ttemplate = \"\"\"Extract all the following values: Invoice ID, DESCRIPTION, Issue Date, \n",
    "\t\tUNIT PRICE, AMOUNT, Bill For, From, and Terms from: {pages}\n",
    "\t\n",
    "\t\tExpected output format (REMOVE DOLLAR SIGNS AND COMMAS):\n",
    "\t\t{{\n",
    "\t\t\t'Invoice ID': '1001329',\n",
    "\t\t\t'DESCRIPTION': 'Professional Services',\n",
    "\t\t\t'Issue Date': '5/4/2023',\n",
    "\t\t\t'UNIT PRICE': '100.00',\n",
    "\t\t\t'AMOUNT': '1100.00',\n",
    "\t\t\t'Bill For': 'James',\n",
    "\t\t\t'From': 'Excel Company',\n",
    "\t\t\t'Terms': 'Due on receipt'\n",
    "\t\t}}\"\"\"\n",
    "\tprompt_template = PromptTemplate(input_variables=[\"pages\"], template=template)\n",
    "\tresponse = llm.invoke(prompt_template.format(pages=pages_data))\n",
    "\treturn response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7a6e3b10-f0d1-4c53-8177-8658097254e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_currency(value):\n",
    "    if isinstance(value, str):\n",
    "        return float(value.replace('$', '').replace(',', '').strip())\n",
    "    return value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b121b289-ba5f-44d3-a788-b2163075e23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_currency(value):\n",
    "    if isinstance(value, str):\n",
    "        return float(value.replace('$', '').replace(',', '').strip())\n",
    "    return value\n",
    "\n",
    "\n",
    "def create_docs(user_pdf_list):\n",
    "    # Initialize DataFrame with proper types\n",
    "    df = pd.DataFrame({\n",
    "        'Invoice ID': pd.Series(dtype='str'),\n",
    "        'DESCRIPTION': pd.Series(dtype='str'),\n",
    "        'Issue Date': pd.Series(dtype='str'),\n",
    "        'UNIT PRICE': pd.Series(dtype='float'),\n",
    "        'AMOUNT': pd.Series(dtype='float'),\n",
    "        'Bill For': pd.Series(dtype='str'),\n",
    "        'From': pd.Series(dtype='str'),\n",
    "        'Terms': pd.Series(dtype='str')\n",
    "    })\n",
    "\n",
    "    for filename in user_pdf_list:\n",
    "        try:\n",
    "            raw_data = get_pdf_text(filename)\n",
    "            llm_extracted_data = extracted_data(raw_data)\n",
    "            \n",
    "            # Extract content between curly braces\n",
    "            pattern = r'{(.+?)}'\n",
    "            match = re.search(pattern, llm_extracted_data, re.DOTALL)\n",
    "            \n",
    "            if not match:\n",
    "                print(\"No valid data found in LLM output\")\n",
    "                continue\n",
    "                \n",
    "            extracted_text = match.group(1).strip()\n",
    "            \n",
    "            try:\n",
    "                # Safely evaluate the string to dictionary\n",
    "                data_dict = literal_eval('{' + extracted_text + '}')\n",
    "                \n",
    "                # Clean currency fields\n",
    "                for money_col in ['UNIT PRICE', 'AMOUNT']:\n",
    "                    if money_col in data_dict:\n",
    "                        data_dict[money_col] = clean_currency(data_dict[money_col])\n",
    "                \n",
    "                # Handle key mismatches\n",
    "                if 'Date' in data_dict and 'Issue Date' not in data_dict:\n",
    "                    data_dict['Issue Date'] = data_dict.pop('Date')\n",
    "                \n",
    "                # Add to DataFrame\n",
    "                df = pd.concat([df, pd.DataFrame([data_dict])], ignore_index=True)\n",
    "                \n",
    "            except (SyntaxError, ValueError, KeyError) as e:\n",
    "                print(f\"Error processing extracted data: {e}\")\n",
    "                continue\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {filename}: {e}\")\n",
    "            continue\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2f6e51a4-9ad6-4ad3-b602-e0fe433839b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/Phone-bill.pdf', 'data/Rental-bill.pdf', 'data/Water-sew-bill.pdf']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "11a52aaf-c157-41eb-a73b-894a1da63629",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "from io import BytesIO\n",
    "from PyPDF2 import PdfReader\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e7b43a35-908e-4a18-8a02-484ba5814b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract text from a PDF\n",
    "def get_pdf_text(uploaded_file):\n",
    "    \"\"\"Extracts text from a PDF file.\"\"\"\n",
    "    text = \"\"\n",
    "    pdf_bytes = BytesIO(uploaded_file.read())  # Read file into a BytesIO object\n",
    "    pdf_reader = PdfReader(pdf_bytes)\n",
    "    \n",
    "    for page in pdf_reader.pages:\n",
    "        text += page.extract_text() if page.extract_text() else \"\"\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8e74775d-37ab-4121-b89f-cafa2f4d49eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Phone BillFrom: DR-TeleP\\n1583 E. TanneVa Ln\\nNekaspo, WE 99010\\nTel #590-327-3987\\nBill For: Paul Regex Invoice ID 2,389\\n1110 112THAVE W, SUITE 89626 Issue Date 11/27/2026\\nSATURNEY, WA 99765 Due Date Upon receipt\\nTel # 12876494 Terms Due upon receipt\\nDESCRIPTION QUANTITY UNIT PRICE AMOUNT\\nPhone and data bill $500.00 $500.00\\n$0.00\\n$0.00\\n$0.00\\n$0.00\\n$0.00\\n$0.00\\n$0.00\\n$0.00\\nSUBTOTAL $500.00\\nTAX RATE 0.00%\\nTAX $0.00\\nAMOUNT DUE $500.00'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"data/Phone-bill.pdf\", \"rb\") as file:\n",
    "    pdf_text = get_pdf_text(BytesIO(file.read()))\n",
    "\n",
    "pdf_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ef4d41ba-d98f-4e27-b3ba-51909744f5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract structured invoice data using LLM\n",
    "def extracted_data(pages_data, llm):\n",
    "    \"\"\"Uses LLM to extract structured invoice data.\"\"\"\n",
    "    template = \"\"\"Extract all the following values: Invoice ID, DESCRIPTION, Issue Date, \n",
    "    UNIT PRICE, AMOUNT, Bill For, From, and Terms from the given text:\n",
    "\n",
    "    {pages}\n",
    "\n",
    "    Expected output format (REMOVE DOLLAR SIGNS AND COMMAS):\n",
    "    {{\n",
    "        \"Invoice ID\": \"1001329\",\n",
    "        \"DESCRIPTION\": \"Professional Services\",\n",
    "        \"Issue Date\": \"5/4/2023\",\n",
    "        \"UNIT PRICE\": \"100.00\",\n",
    "        \"AMOUNT\": \"1100.00\",\n",
    "        \"Bill For\": \"James\",\n",
    "        \"From\": \"Excel Company\",\n",
    "        \"Terms\": \"Due on receipt\"\n",
    "    }}\"\"\"\n",
    "\n",
    "    prompt_template = PromptTemplate(input_variables=[\"pages\"], template=template)\n",
    "\n",
    "    # Generate response from LLM\n",
    "    response = llm.invoke(prompt_template.format(pages=pages_data))\n",
    "\n",
    "    # Handle response content safely\n",
    "    return response.content if hasattr(response, 'content') else str(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "432d6dec-dcb4-4746-9ff1-a44a99a9dab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the extracted values in the expected output format:\n",
      "\n",
      "```\n",
      "{\n",
      "    \"Invoice ID\": \"2389\",\n",
      "    \"DESCRIPTION\": \"Phone and data bill\",\n",
      "    \"Issue Date\": \"11/27/2026\",\n",
      "    \"UNIT PRICE\": \"500.00\",\n",
      "    \"AMOUNT\": \"500.00\",\n",
      "    \"Bill For\": \"Paul Regex\",\n",
      "    \"From\": \"DR-TeleP\",\n",
      "    \"Terms\": \"Due upon receipt\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "data = extracted_data(pdf_text, llm)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f8cae6b2-2bd5-47c9-8cdf-827876577770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean currency values\n",
    "def clean_currency(value):\n",
    "    \"\"\"Removes currency symbols and commas, converts to float.\"\"\"\n",
    "    if isinstance(value, str):\n",
    "        return float(value.replace('$', '').replace(',', '').strip())\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4b4d7dd8-561e-47df-ab5c-071a081b4282",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main function to process PDF invoices\n",
    "def create_docs(user_pdf_list, llm):\n",
    "    \"\"\"Extracts structured invoice data from PDFs and returns a DataFrame.\"\"\"\n",
    "    \n",
    "    # Initialize an empty DataFrame\n",
    "    df = pd.DataFrame(columns=[\n",
    "        'Invoice ID', 'DESCRIPTION', 'Issue Date', 'UNIT PRICE', \n",
    "        'AMOUNT', 'Bill For', 'From', 'Terms'\n",
    "    ])\n",
    "\n",
    "    for file_path in user_pdf_list:\n",
    "        try:\n",
    "            # Open the PDF file\n",
    "            with open(file_path, \"rb\") as file:\n",
    "                raw_data = get_pdf_text(file)  # Extract text\n",
    "            \n",
    "            # Extract structured data using LLM\n",
    "            llm_extracted_data = extracted_data(raw_data, llm)\n",
    "\n",
    "            # Find JSON-like structure in the response\n",
    "            match = re.search(r'\\{.*\\}', llm_extracted_data, re.DOTALL)\n",
    "            if not match:\n",
    "                print(f\"⚠️ No structured data found in LLM response for {file_path}\")\n",
    "                continue\n",
    "            \n",
    "            extracted_text = match.group(0).strip()  # Extract full JSON-like text\n",
    "\n",
    "            try:\n",
    "                # Convert extracted JSON string into a dictionary\n",
    "                data_dict = json.loads(extracted_text)\n",
    "\n",
    "                # Clean currency fields\n",
    "                for money_col in ['UNIT PRICE', 'AMOUNT']:\n",
    "                    if money_col in data_dict:\n",
    "                        data_dict[money_col] = clean_currency(data_dict[money_col])\n",
    "                \n",
    "                # Handle key mismatches (e.g., \"Date\" instead of \"Issue Date\")\n",
    "                if 'Date' in data_dict and 'Issue Date' not in data_dict:\n",
    "                    data_dict['Issue Date'] = data_dict.pop('Date')\n",
    "                \n",
    "                # Append extracted data to the DataFrame\n",
    "                df.loc[len(df)] = data_dict  # Faster than using pd.concat()\n",
    "\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"❌ JSON parsing error in {file_path}: {e}\")\n",
    "                continue\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error processing file {file_path}: {e}\")\n",
    "            continue\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "60499a14-0a86-443e-9dcb-ee94e1f33059",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm  =  ChatGroq(api_key=GROQ_API,\n",
    "    model_name=model_name,\n",
    "    temperature=0.0,\n",
    "    \n",
    ")\n",
    "\n",
    "files = os.listdir('data')\n",
    "files_list = [ f\"data/{f}\"  for f in files]\n",
    "df = create_docs(files_list, llm)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "25941acf-6514-4533-8626-4162253d82d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Invoice ID</th>\n",
       "      <th>DESCRIPTION</th>\n",
       "      <th>Issue Date</th>\n",
       "      <th>UNIT PRICE</th>\n",
       "      <th>AMOUNT</th>\n",
       "      <th>Bill For</th>\n",
       "      <th>From</th>\n",
       "      <th>Terms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2389</td>\n",
       "      <td>Phone and data bill</td>\n",
       "      <td>11/27/2026</td>\n",
       "      <td>500.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>Paul Regex</td>\n",
       "      <td>DR-TeleP</td>\n",
       "      <td>Due upon receipt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000</td>\n",
       "      <td>Condo Rental</td>\n",
       "      <td>11/27/2026</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>Paul Regex</td>\n",
       "      <td>DR-TeleP</td>\n",
       "      <td>Due upon receipt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000</td>\n",
       "      <td>Water and Sewage</td>\n",
       "      <td>11/27/2026</td>\n",
       "      <td>134.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>Paul Regex</td>\n",
       "      <td>DR-TeleP</td>\n",
       "      <td>Due upon receipt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Invoice ID          DESCRIPTION  Issue Date  UNIT PRICE  AMOUNT    Bill For  \\\n",
       "0       2389  Phone and data bill  11/27/2026       500.0   500.0  Paul Regex   \n",
       "1       1000         Condo Rental  11/27/2026      2500.0  2500.0  Paul Regex   \n",
       "2       1000     Water and Sewage  11/27/2026       134.0   134.0  Paul Regex   \n",
       "\n",
       "       From             Terms  \n",
       "0  DR-TeleP  Due upon receipt  \n",
       "1  DR-TeleP  Due upon receipt  \n",
       "2  DR-TeleP  Due upon receipt  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f809bc-35a6-476b-abd4-9a8adcf864ac",
   "metadata": {},
   "source": [
    "# AI-Tech-Newslette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eda8e486-d68a-4299-b4e1-bc84ceede257",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import faiss\n",
    "import json\n",
    "import numpy as np\n",
    "import streamlit as st\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "from langchain import LLMChain, PromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain_community.document_loaders import UnstructuredURLLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_community.tools import TavilySearchResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "721b9614-1db6-4299-b5af-3097f6f88223",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "load_dotenv(find_dotenv())\n",
    "os.environ[\"TAVILY_API_KEY\"] = os.getenv(\"TAVILY_API_KEY\")\n",
    "GROQ_API = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "# Initialize LLM once to avoid re-instantiating in functions\n",
    "model_name = 'llama-3.3-70b-versatile'\n",
    "llm = ChatGroq(api_key=GROQ_API, model_name=model_name, temperature=0.0)\n",
    "\n",
    "# Initialize OpenAI Embeddings\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "# FAISS Index\n",
    "dimension = 1536  # OpenAI's embedding dimension\n",
    "index = faiss.IndexFlatL2(dimension)\n",
    "documents = []  # Store document texts separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c2db5ab-61b7-4bf9-9811-2afd24a26e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_tavily(query: str, max_results: int = 5) -> dict:\n",
    "    \"\"\"\n",
    "    Searches for relevant articles using TavilySearchResults.\n",
    "    \"\"\"\n",
    "    tool = TavilySearchResults(max_results=max_results)\n",
    "    response_json = tool.invoke({\"query\": query})\n",
    "    print(f\"Response JSON from SERP: {response_json}\")\n",
    "    return response_json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3303022-a997-4e38-9855-72e1d6da7596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response JSON from SERP: [{'title': 'Entire families killed in Syria sectarian violence, UN says | CNN', 'url': 'https://www.cnn.com/2025/03/12/middleeast/syria-sectarian-violence-un-ohcr-intl-hnk/index.html', 'content': 'Armed groups killed entire families, including women and children, during an outbreak of sectarian violence in Syria last week,', 'score': 0.6698534}, {'title': \"Syria | Today's latest from Al Jazeera\", 'url': 'https://www.aljazeera.com/where/syria/', 'content': 'Thousands of Syrians flee to Lebanon after clashes between government forces and pro-Assad fighters led to mass killings.', 'score': 0.44261298}, {'title': 'Entire families killed during recent violence in Syria, UN says - BBC', 'url': 'https://www.bbc.com/news/articles/cedlx65988qo', 'content': 'The violence escalated on Thursday, after 13 security personnel were killed in an ambush by gunmen in the coastal town of Jableh. Security', 'score': 0.41094592}, {'title': 'Syria news - breaking stories, video, analysis and opinion - CNN', 'url': 'https://www.cnn.com/world/middleeast/syria', 'content': 'Syria news - breaking stories, video, analysis and opinion | CNN CNN values your feedback Africa Americas Asia Australia China Europe India Middle East United Kingdom Your CNN account Sign in to your CNN account Follow CNN CNN Headlines CNN Shorts CNN10 CNN Max CNN TV Schedules CNN 5 Things CNN Political Briefing CNN Underscored CNN Crossword About CNN CNN Profiles CNN Leadership CNN Newsletters Work for CNN Getty ImagesVideo CNN 10: The big stories of Friday 1/31, explained in 10 minutes 10:00 Jan 30, 2025 CNN Headlines CNN Shorts CNN10 CNN Max CNN TV Schedules CNN 5 Things CNN Political Briefing CNN Underscored CNN Crossword About CNN CNN Profiles CNN Leadership CNN Newsletters Work for CNN Follow CNN', 'score': 0.20220715}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'title': 'Entire families killed in Syria sectarian violence, UN says | CNN',\n",
       "  'url': 'https://www.cnn.com/2025/03/12/middleeast/syria-sectarian-violence-un-ohcr-intl-hnk/index.html',\n",
       "  'content': 'Armed groups killed entire families, including women and children, during an outbreak of sectarian violence in Syria last week,',\n",
       "  'score': 0.6698534},\n",
       " {'title': \"Syria | Today's latest from Al Jazeera\",\n",
       "  'url': 'https://www.aljazeera.com/where/syria/',\n",
       "  'content': 'Thousands of Syrians flee to Lebanon after clashes between government forces and pro-Assad fighters led to mass killings.',\n",
       "  'score': 0.44261298},\n",
       " {'title': 'Entire families killed during recent violence in Syria, UN says - BBC',\n",
       "  'url': 'https://www.bbc.com/news/articles/cedlx65988qo',\n",
       "  'content': 'The violence escalated on Thursday, after 13 security personnel were killed in an ambush by gunmen in the coastal town of Jableh. Security',\n",
       "  'score': 0.41094592},\n",
       " {'title': 'Syria news - breaking stories, video, analysis and opinion - CNN',\n",
       "  'url': 'https://www.cnn.com/world/middleeast/syria',\n",
       "  'content': 'Syria news - breaking stories, video, analysis and opinion | CNN CNN values your feedback Africa Americas Asia Australia China Europe India Middle East United Kingdom Your CNN account Sign in to your CNN account Follow CNN CNN Headlines CNN Shorts CNN10 CNN Max CNN TV Schedules CNN 5 Things CNN Political Briefing CNN Underscored CNN Crossword About CNN CNN Profiles CNN Leadership CNN Newsletters Work for CNN Getty ImagesVideo CNN 10: The big stories of Friday 1/31, explained in 10 minutes 10:00 Jan 30, 2025 CNN Headlines CNN Shorts CNN10 CNN Max CNN TV Schedules CNN 5 Things CNN Political Briefing CNN Underscored CNN Crossword About CNN CNN Profiles CNN Leadership CNN Newsletters Work for CNN Follow CNN',\n",
       "  'score': 0.20220715}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What happen last week in syria\"\n",
    "search_results = search_tavily(query=query)\n",
    "search_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad52ca5e-6584-4b28-9658-e79f49e085fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_best_articles_urls(response_json: dict, query: str) -> list:\n",
    "    \"\"\"\n",
    "    Uses an LLM to select the best articles from search results and return a list of URLs.\n",
    "    \"\"\"\n",
    "    response_str = json.dumps(response_json)\n",
    "\n",
    "    prompt_template = PromptTemplate(\n",
    "        input_variables=[\"response_str\", \"query\"],\n",
    "        template=\"\"\"\n",
    "          You are a world-class journalist, researcher, and tech expert.\n",
    "          You excel at selecting the most relevant and high-quality articles.\n",
    "\n",
    "          SEARCH RESULTS: {response_str}\n",
    "\n",
    "          QUERY: {query}\n",
    "\n",
    "          Select the best 3 articles and return ONLY an array of their URLs.\n",
    "          If a URL is invalid, replace it with 'www.google.com'.\n",
    "\n",
    "          Return ONLY a JSON array with the URLs.\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    article_chooser_chain = LLMChain(llm=llm, prompt=prompt_template, verbose=False)\n",
    "\n",
    "    try:\n",
    "        urls_str = article_chooser_chain.run(response_str=response_str, query=query)\n",
    "        url_list = json.loads(urls_str)\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"Warning: LLM did not return valid JSON. Returning an empty list.\")\n",
    "        url_list = []\n",
    "\n",
    "    return [\"https://www.google.com\" if not url.startswith(\"http\") else url for url in url_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e110d06e-79ca-4a29-879c-415c89e4319e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ibrah\\AppData\\Local\\Temp\\ipykernel_22648\\507571347.py:24: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  article_chooser_chain = LLMChain(llm=llm, prompt=prompt_template, verbose=False)\n",
      "C:\\Users\\ibrah\\AppData\\Local\\Temp\\ipykernel_22648\\507571347.py:27: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  urls_str = article_chooser_chain.run(response_str=response_str, query=query)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['https://www.cnn.com/2025/03/12/middleeast/syria-sectarian-violence-un-ohcr-intl-hnk/index.html',\n",
       " 'https://www.aljazeera.com/where/syria/',\n",
       " 'https://www.bbc.com/news/articles/cedlx65988qo']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls = pick_best_articles_urls(response_json=search_results, query=query)\n",
    "urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f738882b-f147-4730-9947-1820eed1f7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_content_from_urls(urls: list):\n",
    "    \"\"\"\n",
    "    Loads and processes content from URLs, then stores it in a FAISS vector database.\n",
    "    \"\"\"\n",
    "    global index, documents\n",
    "\n",
    "    loader = UnstructuredURLLoader(urls=urls)\n",
    "    data = loader.load()\n",
    "\n",
    "    text_splitter = CharacterTextSplitter(\n",
    "        separator=\"\\n\", chunk_size=1000, chunk_overlap=200, length_function=len\n",
    "    )\n",
    "    docs = text_splitter.split_documents(data)\n",
    "\n",
    "    # Convert text into embeddings and store in FAISS\n",
    "    text_embeddings = []\n",
    "    for doc in docs:\n",
    "        embedding = embeddings.embed_query(doc.page_content)\n",
    "        text_embeddings.append(embedding)\n",
    "        documents.append(doc.page_content)  # Store actual text\n",
    "\n",
    "    text_embeddings = np.array(text_embeddings, dtype='float32')\n",
    "    \n",
    "    if len(text_embeddings) > 0:\n",
    "        index.add(text_embeddings)  # Add to FAISS index\n",
    "\n",
    "    return index  # Return FAISS index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "952cf4d4-1177-4af4-94bb-169ef966b819",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "extract_content_from_urls(urls)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "05ea6471-a586-47ef-9c30-9abf8755a6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarizer(query: str, k: int = 4) -> str:\n",
    "    \"\"\"\n",
    "    Retrieves relevant document chunks from FAISS and summarizes them using LLM.\n",
    "    \"\"\"\n",
    "    global index, documents\n",
    "\n",
    "    query_embedding = np.array([embeddings.embed_query(query)], dtype='float32')\n",
    "\n",
    "    # Perform similarity search in FAISS\n",
    "    _, nearest_indices = index.search(query_embedding, k)\n",
    "    \n",
    "    retrieved_docs = [documents[i] for i in nearest_indices[0] if i < len(documents)]\n",
    "    docs_page_content = \" \".join(retrieved_docs) if retrieved_docs else \"No relevant content found.\"\n",
    "\n",
    "    prompt_template = PromptTemplate(\n",
    "        input_variables=[\"docs\", \"query\"],\n",
    "        template=\"\"\"\n",
    "           {docs}\n",
    "           You are a top journalist and researcher. Write a concise and engaging newsletter summary about {query}.\n",
    "           Ensure that:\n",
    "             1) The content is informative and engaging.\n",
    "             2) The length is appropriate for a newsletter.\n",
    "             3) Insights, practical advice, and links (if necessary) are included.\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    summarizer_chain = LLMChain(llm=llm, prompt=prompt_template, verbose=False)\n",
    "    response = summarizer_chain.run(docs=docs_page_content, query=query)\n",
    "\n",
    "    return response.replace(\"\\n\", \" \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94896946-ca34-40bf-8b18-3ec35496f29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries = summarizer(query)\n",
    "display(Markdown(summaries))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4586ae-2919-4aea-b618-92cbde8a9b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_results = search_tavily(query=query)\n",
    "urls = pick_best_articles_urls(response_json=search_results, query=query)\n",
    "extract_content_from_urls(urls)\n",
    "summaries = summarizer(query)\n",
    "newsletter_thread = generate_newsletter(summaries, query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_langchain",
   "language": "python",
   "name": "env_langchain"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
